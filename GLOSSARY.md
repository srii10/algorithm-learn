# üìñ Glossaire Complet - Algorithmes et Structures de Donn√©es

Ce glossaire regroupe tous les termes techniques, concepts algorithmiques et structures de donn√©es abord√©s dans la formation **¬´ Algorithmes : des fondamentaux aux concepts avanc√©s avec JavaScript ¬ª**. Les termes sont organis√©s par module pour faciliter la navigation et la r√©vision.

---

## Table des Mati√®res

- [Module 1 : Fondements des Algorithmes et JavaScript](#module-1--fondements-des-algorithmes-et-javascript)
- [Module 2 : Structures de Donn√©es Essentielles](#module-2--structures-de-donn√©es-essentielles)
- [Module 3 : Techniques de Tri Essentielles](#module-3--techniques-de-tri-essentielles)
- [Module 4 : Recherche et R√©cursion](#module-4--recherche-et-r√©cursion)
- [Module 5 : Arbres et Parcours de Graphes](#module-5--arbres-et-parcours-de-graphes)
- [Module 6 : Paradigmes Avanc√©s de Conception d'Algorithmes](#module-6--paradigmes-avanc√©s-de-conception-dalgorithmes)
- [Module 7 : R√©vision et Pratique Avanc√©e](#module-7--r√©vision-et-pratique-avanc√©e)
- [Termes G√©n√©raux](#-termes-g√©n√©raux)
- [Tableaux R√©capitulatifs](#-tableaux-r√©capitulatifs)

---

## Module 1 : Fondements des Algorithmes et JavaScript

### Algorithme

**D√©finition** : S√©quence finie et ordonn√©e d'instructions claires et non ambigu√´s permettant de r√©soudre un probl√®me ou d'accomplir une t√¢che sp√©cifique.

**Caract√©ristiques** :

- **Finitude** : Se termine apr√®s un nombre fini d'√©tapes
- **Pr√©cision** : Chaque instruction est claire et sans ambigu√Øt√©
- **Entr√©e** : Z√©ro ou plusieurs donn√©es d'entr√©e
- **Sortie** : Au moins un r√©sultat produit
- **Efficacit√©** : Utilise les ressources (temps, m√©moire) de mani√®re raisonnable

---

### Big O (Notation Big O)

**D√©finition** : Notation math√©matique d√©crivant la **complexit√© asymptotique** d'un algorithme, c'est-√†-dire comment le temps d'ex√©cution ou l'espace m√©moire cro√Æt en fonction de la taille de l'entr√©e (n).

**Complexit√©s courantes** (du plus rapide au plus lent) :

- **O(1)** : Constant - Le temps d'ex√©cution ne d√©pend pas de la taille de l'entr√©e
- **O(log n)** : Logarithmique - Double la taille de l'entr√©e = +1 op√©ration (ex: recherche binaire)
- **O(n)** : Lin√©aire - Double la taille = double le temps (ex: parcours de tableau)
- **O(n log n)** : Quasi-lin√©aire - Complexit√© des meilleurs algorithmes de tri (merge sort, quick sort)
- **O(n¬≤)** : Quadratique - Double la taille = 4√ó le temps (ex: tri √† bulles)
- **O(2‚Åø)** : Exponentiel - Croissance tr√®s rapide, impraticable pour n > 30 (ex: Fibonacci na√Øf)
- **O(n!)** : Factorielle - Croissance encore plus rapide (ex: probl√®me du voyageur de commerce brute force)

**Exemple** :

```javascript
// O(1) - Temps constant
function obtenirPremier(arr) {
  return arr[0];
}

// O(n) - Temps lin√©aire
function somme(arr) {
  let total = 0;
  for (let i = 0; i < arr.length; i++) {
    total += arr[i];
  }
  return total;
}

// O(n¬≤) - Temps quadratique
function pairesDoublons(arr) {
  for (let i = 0; i < arr.length; i++) {
    for (let j = 0; j < arr.length; j++) {
      console.log(arr[i], arr[j]);
    }
  }
}
```

---

### Complexit√© Temporelle

**D√©finition** : Mesure du **nombre d'op√©rations** (ou du temps d'ex√©cution) que n√©cessite un algorithme en fonction de la taille de l'entr√©e.

**Usage** : Permet de comparer l'efficacit√© de diff√©rents algorithmes et de pr√©dire comment un algorithme √©voluera avec des ensembles de donn√©es plus grands.

---

### Complexit√© Spatiale

**D√©finition** : Mesure de la **quantit√© de m√©moire** utilis√©e par un algorithme en fonction de la taille de l'entr√©e, incluant les variables locales, les structures de donn√©es auxiliaires, et la pile d'appels (pour les algorithmes r√©cursifs).

**Exemple** :

```javascript
// Complexit√© spatiale O(1) - Espace constant
function sommeTabulationOptimise(n) {
  let prev = 0,
    curr = 1;
  for (let i = 2; i <= n; i++) {
    let next = prev + curr;
    prev = curr;
    curr = next;
  }
  return curr;
}

// Complexit√© spatiale O(n) - Espace lin√©aire
function sommeTabulationTableau(n) {
  const dp = Array(n + 1).fill(0);
  dp[0] = 0;
  dp[1] = 1;
  for (let i = 2; i <= n; i++) {
    dp[i] = dp[i - 1] + dp[i - 2];
  }
  return dp[n];
}
```

---

### Efficacit√© Algorithmique

**D√©finition** : Mesure de la qualit√© d'un algorithme en termes de ressources consomm√©es (temps d'ex√©cution et m√©moire). Un algorithme efficace minimise ces deux aspects tout en restant correct.

**Crit√®res d'√©valuation** :

- Vitesse d'ex√©cution
- Utilisation de la m√©moire
- Scalabilit√© (comportement avec de grandes donn√©es)
- Lisibilit√© et maintenabilit√© du code

---

### Scalabilit√©

**D√©finition** : Capacit√© d'un algorithme ou syst√®me √† maintenir des performances acceptables lorsque la taille des donn√©es augmente significativement.

**Exemple** : Un algorithme O(n log n) est plus scalable qu'un algorithme O(n¬≤) car il reste performant m√™me avec de tr√®s grandes valeurs de n.

---

### Pire Cas, Meilleur Cas, Cas Moyen

**D√©finition** : Trois sc√©narios d'analyse de la complexit√© d'un algorithme :

- **Pire cas** : Situation o√π l'algorithme prend le plus de temps (g√©n√©ralement ce qu'on utilise pour Big O)
- **Meilleur cas** : Situation optimale o√π l'algorithme est le plus rapide
- **Cas moyen** : Performance attendue sur un √©chantillon repr√©sentatif de donn√©es

**Exemple avec la recherche lin√©aire** :

- **Meilleur cas** : O(1) - L'√©l√©ment est en premi√®re position
- **Pire cas** : O(n) - L'√©l√©ment est en derni√®re position ou absent
- **Cas moyen** : O(n/2) ‚âà O(n) - L'√©l√©ment est quelque part au milieu

---

### Pens√©e Algorithmique

**D√©finition** : Comp√©tence cognitive permettant de d√©composer un probl√®me complexe en √©tapes logiques et s√©quentielles pour le r√©soudre de mani√®re syst√©matique.

**√âtapes** :

1. **Comprendre** le probl√®me
2. **D√©composer** en sous-probl√®mes plus simples
3. **Concevoir** une solution √©tape par √©tape
4. **Analyser** l'efficacit√© de la solution
5. **Optimiser** si n√©cessaire

---

## Module 2 : Structures de Donn√©es Essentielles

### Tableau (Array)

**D√©finition** : Structure de donn√©es **lin√©aire** qui stocke des √©l√©ments de mani√®re **contigu√´** en m√©moire, accessibles par un **index num√©rique**.

**Caract√©ristiques en JavaScript** :

- Taille dynamique (peut grandir ou r√©tr√©cir)
- Peut contenir des types mixtes
- Indexation commence √† 0

**Complexit√© des op√©rations** :

- **Acc√®s par index** : O(1)
- **Recherche** : O(n)
- **Insertion en fin** : O(1) amortis√©
- **Insertion au d√©but/milieu** : O(n)
- **Suppression** : O(n)

---

### Liste Cha√Æn√©e (Linked List)

**D√©finition** : Structure de donn√©es **lin√©aire** compos√©e de **n≈ìuds** o√π chaque n≈ìud contient une valeur et une **r√©f√©rence** (pointeur) vers le n≈ìud suivant.

**Types** :

- **Liste simplement cha√Æn√©e** : Chaque n≈ìud pointe uniquement vers le suivant
- **Liste doublement cha√Æn√©e** : Chaque n≈ìud pointe vers le suivant ET le pr√©c√©dent
- **Liste circulaire** : Le dernier n≈ìud pointe vers le premier

**Complexit√© des op√©rations** :

- **Acc√®s par index** : O(n)
- **Recherche** : O(n)
- **Insertion en t√™te** : O(1)
- **Insertion en fin** : O(n) pour simplement cha√Æn√©e, O(1) avec pointeur tail
- **Suppression en t√™te** : O(1)

**Exemple de structure de n≈ìud** :

```javascript
class Node {
  constructor(value) {
    this.value = value;
    this.next = null; // R√©f√©rence vers le n≈ìud suivant
  }
}
```

**Avantages** :

- Insertion/suppression en t√™te tr√®s rapide O(1)
- Pas de redimensionnement comme les tableaux
- Taille dynamique sans limite

**Inconv√©nients** :

- Acc√®s par index lent O(n)
- Utilise plus de m√©moire (stockage des r√©f√©rences)
- Mauvaise localit√© m√©moire (cache CPU moins efficace)

---

### Pile (Stack)

**D√©finition** : Structure de donn√©es **LIFO** (Last In, First Out) o√π le dernier √©l√©ment ajout√© est le premier √† √™tre retir√©. Comme une pile d'assiettes.

**Op√©rations principales** :

- **push(element)** : Ajouter un √©l√©ment au sommet - O(1)
- **pop()** : Retirer l'√©l√©ment au sommet - O(1)
- **peek()** / **top()** : Consulter l'√©l√©ment au sommet sans le retirer - O(1)
- **isEmpty()** : V√©rifier si la pile est vide - O(1)

**Cas d'usage** :

- Historique de navigation (bouton "Retour")
- Annuler/Refaire (Undo/Redo)
- Pile d'appels de fonctions (call stack)
- √âvaluation d'expressions math√©matiques
- Parcours en profondeur (DFS)

**Impl√©mentation** :

```javascript
class Stack {
  constructor() {
    this.items = [];
  }

  push(element) {
    this.items.push(element);
  }

  pop() {
    return this.items.pop();
  }

  peek() {
    return this.items[this.items.length - 1];
  }

  isEmpty() {
    return this.items.length === 0;
  }
}
```

---

### File (Queue)

**D√©finition** : Structure de donn√©es **FIFO** (First In, First Out) o√π le premier √©l√©ment ajout√© est le premier √† √™tre retir√©. Comme une file d'attente au supermarch√©.

**Op√©rations principales** :

- **enqueue(element)** : Ajouter un √©l√©ment √† la fin - O(1)
- **dequeue()** : Retirer l'√©l√©ment au d√©but - O(1)
- **front()** / **peek()** : Consulter l'√©l√©ment au d√©but sans le retirer - O(1)
- **isEmpty()** : V√©rifier si la file est vide - O(1)

**Cas d'usage** :

- File d'attente d'impressions
- Gestion de requ√™tes serveur
- Parcours en largeur (BFS)
- Tampons de donn√©es (buffers)
- Syst√®mes de messagerie (queues)

**Impl√©mentation** :

```javascript
class Queue {
  constructor() {
    this.items = [];
  }

  enqueue(element) {
    this.items.push(element);
  }

  dequeue() {
    return this.items.shift();
  }

  front() {
    return this.items[0];
  }

  isEmpty() {
    return this.items.length === 0;
  }
}
```

---

### LIFO (Last In, First Out)

**D√©finition** : Principe de gestion o√π le dernier √©l√©ment ajout√© est le premier √† √™tre retir√©. Caract√©ristique fondamentale des **piles**.

---

### FIFO (First In, First Out)

**D√©finition** : Principe de gestion o√π le premier √©l√©ment ajout√© est le premier √† √™tre retir√©. Caract√©ristique fondamentale des **files**.

---

### N≈ìud (Node)

**D√©finition** : √âl√©ment de base d'une structure de donn√©es cha√Æn√©e (liste cha√Æn√©e, arbre, graphe) contenant :

- Une **valeur** (donn√©es stock√©es)
- Une ou plusieurs **r√©f√©rences** vers d'autres n≈ìuds

**Exemple** :

```javascript
class Node {
  constructor(value) {
    this.value = value;
    this.next = null; // Pour liste cha√Æn√©e simple
    // this.prev = null; // Pour liste doublement cha√Æn√©e
  }
}
```

---

### R√©f√©rence / Pointeur

**D√©finition** : Variable qui contient l'**adresse m√©moire** d'un autre objet plut√¥t que la valeur elle-m√™me. En JavaScript, les objets sont manipul√©s par r√©f√©rence.

**Exemple** :

```javascript
let noeud1 = { value: 10, next: null };
let noeud2 = { value: 20, next: null };
noeud1.next = noeud2; // noeud1.next pointe vers noeud2
```

---

## Module 3 : Techniques de Tri Essentielles

### Tri (Sorting)

**D√©finition** : Processus de **r√©organisation** d'une collection d'√©l√©ments dans un ordre sp√©cifique (croissant ou d√©croissant) selon un crit√®re de comparaison.

**Importance** :

- Facilite la recherche (recherche binaire n√©cessite un tableau tri√©)
- Am√©liore la lisibilit√© des donn√©es
- Optimise certains algorithmes

---

### Tri √† Bulles (Bubble Sort)

**D√©finition** : Algorithme de tri simple qui **compare** des paires d'√©l√©ments adjacents et les **√©change** si n√©cessaire, r√©p√©tant ce processus jusqu'√† ce que le tableau soit tri√©.

**Complexit√©** :

- **Temps** : O(n¬≤) dans le pire et le cas moyen, O(n) dans le meilleur cas (d√©j√† tri√© avec optimisation)
- **Espace** : O(1) - Tri en place

**Principe** : Les √©l√©ments "remontent" comme des bulles vers leur position finale.

**Impl√©mentation** :

```javascript
function triBulles(arr) {
  const n = arr.length;
  for (let i = 0; i < n - 1; i++) {
    let echange = false;
    for (let j = 0; j < n - 1 - i; j++) {
      if (arr[j] > arr[j + 1]) {
        [arr[j], arr[j + 1]] = [arr[j + 1], arr[j]]; // √âchange
        echange = true;
      }
    }
    if (!echange) break; // Optimisation
  }
  return arr;
}
```

**Usage** : P√©dagogique uniquement, inefficace en pratique.

---

### Tri par S√©lection (Selection Sort)

**D√©finition** : Algorithme de tri qui **s√©lectionne** le plus petit √©l√©ment non tri√© et le **place** √† sa position finale, r√©p√©tant ce processus pour tous les √©l√©ments.

**Complexit√©** :

- **Temps** : O(n¬≤) dans tous les cas
- **Espace** : O(1) - Tri en place

**Principe** : Divise le tableau en deux parties (tri√©e et non tri√©e), et d√©place progressivement les √©l√©ments de la partie non tri√©e vers la partie tri√©e.

**Impl√©mentation** :

```javascript
function triSelection(arr) {
  const n = arr.length;
  for (let i = 0; i < n - 1; i++) {
    let indexMin = i;
    for (let j = i + 1; j < n; j++) {
      if (arr[j] < arr[indexMin]) {
        indexMin = j;
      }
    }
    if (indexMin !== i) {
      [arr[i], arr[indexMin]] = [arr[indexMin], arr[i]];
    }
  }
  return arr;
}
```

**Avantage** : Nombre minimal d'√©changes (au plus n-1).

---

### Tri par Insertion (Insertion Sort)

**D√©finition** : Algorithme de tri qui **ins√®re** chaque √©l√©ment √† sa position correcte dans une partie d√©j√† tri√©e du tableau, comme on trie des cartes √† jouer.

**Complexit√©** :

- **Temps** : O(n¬≤) dans le pire cas, O(n) dans le meilleur cas (d√©j√† tri√©)
- **Espace** : O(1) - Tri en place

**Principe** : Construit progressivement une partie tri√©e en ins√©rant chaque nouvel √©l√©ment √† sa place.

**Impl√©mentation** :

```javascript
function triInsertion(arr) {
  for (let i = 1; i < arr.length; i++) {
    let cle = arr[i];
    let j = i - 1;
    while (j >= 0 && arr[j] > cle) {
      arr[j + 1] = arr[j];
      j--;
    }
    arr[j + 1] = cle;
  }
  return arr;
}
```

**Avantages** :

- Efficace pour petits tableaux
- Efficace pour tableaux presque tri√©s
- Stable (pr√©serve l'ordre des √©l√©ments √©gaux)
- Tri en ligne (peut trier les donn√©es au fur et √† mesure de leur arriv√©e)

---

### Tri Fusion (Merge Sort)

**D√©finition** : Algorithme de tri bas√© sur le paradigme **Diviser pour R√©gner** qui **divise** r√©cursivement le tableau en deux moiti√©s, les trie s√©par√©ment, puis **fusionne** les r√©sultats.

**Complexit√©** :

- **Temps** : O(n log n) dans tous les cas
- **Espace** : O(n) - N√©cessite des tableaux auxiliaires

**Principe** :

1. **Diviser** : S√©parer le tableau en deux moiti√©s
2. **R√©gner** : Trier r√©cursivement chaque moiti√©
3. **Combiner** : Fusionner les deux moiti√©s tri√©es

**Impl√©mentation** :

```javascript
function triFusion(arr) {
  if (arr.length <= 1) return arr;

  const milieu = Math.floor(arr.length / 2);
  const gauche = triFusion(arr.slice(0, milieu));
  const droite = triFusion(arr.slice(milieu));

  return fusionner(gauche, droite);
}

function fusionner(gauche, droite) {
  const resultat = [];
  let i = 0,
    j = 0;

  while (i < gauche.length && j < droite.length) {
    if (gauche[i] <= droite[j]) {
      resultat.push(gauche[i++]);
    } else {
      resultat.push(droite[j++]);
    }
  }

  return resultat.concat(gauche.slice(i)).concat(droite.slice(j));
}
```

**Avantages** :

- Garantie O(n log n) dans tous les cas
- Stable
- Bon pour trier de grandes donn√©es
- Parall√©lisable

**Inconv√©nient** : Utilise O(n) espace suppl√©mentaire

---

### Tri Rapide (Quick Sort)

**D√©finition** : Algorithme de tri bas√© sur **Diviser pour R√©gner** qui s√©lectionne un **pivot**, partitionne le tableau en √©l√©ments < pivot et > pivot, puis trie r√©cursivement chaque partition.

**Complexit√©** :

- **Temps** : O(n log n) en moyenne, O(n¬≤) dans le pire cas (pivot mal choisi)
- **Espace** : O(log n) pour la pile d'appels r√©cursifs

**Principe** :

1. **Choisir** un pivot (premier, dernier, al√©atoire, m√©dian)
2. **Partitionner** : Placer tous les √©l√©ments < pivot √† gauche, > pivot √† droite
3. **R√©cursion** : Trier r√©cursivement gauche et droite

**Impl√©mentation** :

```javascript
function triRapide(arr, debut = 0, fin = arr.length - 1) {
  if (debut < fin) {
    const indexPivot = partitionner(arr, debut, fin);
    triRapide(arr, debut, indexPivot - 1);
    triRapide(arr, indexPivot + 1, fin);
  }
  return arr;
}

function partitionner(arr, debut, fin) {
  const pivot = arr[fin];
  let i = debut - 1;

  for (let j = debut; j < fin; j++) {
    if (arr[j] < pivot) {
      i++;
      [arr[i], arr[j]] = [arr[j], arr[i]];
    }
  }

  [arr[i + 1], arr[fin]] = [arr[fin], arr[i + 1]];
  return i + 1;
}
```

**Avantages** :

- Tr√®s rapide en pratique (meilleur tri g√©n√©ral)
- Tri en place (O(1) espace hors pile r√©cursive)
- Cache-friendly (bonne localit√© m√©moire)

**Inconv√©nients** :

- Pire cas O(n¬≤) (peut √™tre √©vit√© avec bon choix de pivot)
- Non stable

---

### Diviser pour R√©gner (Divide and Conquer)

**D√©finition** : Paradigme de conception d'algorithmes qui consiste √† :

1. **Diviser** le probl√®me en sous-probl√®mes plus petits
2. **R√©gner** en r√©solvant r√©cursivement chaque sous-probl√®me
3. **Combiner** les solutions pour obtenir la solution globale

**Exemples** : Tri fusion, tri rapide, recherche binaire, multiplication de matrices

---

### Pivot

**D√©finition** : Dans le tri rapide, √©l√©ment choisi pour **partitionner** le tableau. Tous les √©l√©ments < pivot vont √† gauche, tous les √©l√©ments > pivot vont √† droite.

**Strat√©gies de choix** :

- Premier √©l√©ment (simple mais peut donner O(n¬≤))
- Dernier √©l√©ment (standard)
- √âl√©ment du milieu
- Al√©atoire (√©vite le pire cas)
- M√©diane de trois (premier, milieu, dernier)

---

### Partitionnement (Partitioning)

**D√©finition** : Processus de r√©organisation d'un tableau autour d'un pivot de sorte que tous les √©l√©ments inf√©rieurs au pivot soient √† gauche et tous les √©l√©ments sup√©rieurs soient √† droite.

**Utilis√© dans** : Tri rapide, s√©lection du k-i√®me √©l√©ment

---

### Tri Stable

**D√©finition** : Un algorithme de tri est dit **stable** s'il pr√©serve l'ordre relatif des √©l√©ments √©gaux.

**Exemple** :

```javascript
// Donn√©es : [{nom: "Chermann", √¢ge: 25}, {nom: "Prudence", √¢ge: 25}]
// Tri stable par √¢ge ‚Üí L'ordre Chermann-Prudence est pr√©serv√©
```

**Tris stables** : Tri fusion, tri par insertion, tri √† bulles
**Tris non stables** : Tri rapide, tri par s√©lection, tri par tas

---

### Tri en Place (In-Place Sorting)

**D√©finition** : Algorithme de tri qui ne n√©cessite qu'une quantit√© **constante** O(1) de m√©moire suppl√©mentaire (hors structure de donn√©es d'entr√©e).

**Tris en place** : Tri rapide, tri par s√©lection, tri √† bulles, tri par insertion
**Tris non en place** : Tri fusion (O(n) espace)

---

## Module 4 : Recherche et R√©cursion

### Recherche Lin√©aire (Linear Search)

**D√©finition** : Algorithme de recherche qui **parcourt** s√©quentiellement tous les √©l√©ments d'une collection jusqu'√† trouver l'√©l√©ment recherch√©.

**Complexit√©** :

- **Temps** : O(n) dans le pire cas
- **Espace** : O(1)

**Impl√©mentation** :

```javascript
function rechercheLineaire(arr, cible) {
  for (let i = 0; i < arr.length; i++) {
    if (arr[i] === cible) {
      return i; // Index de l'√©l√©ment trouv√©
    }
  }
  return -1; // √âl√©ment non trouv√©
}
```

**Avantages** :

- Fonctionne sur tableaux non tri√©s
- Simple √† impl√©menter

**Inconv√©nient** : Lent pour grandes collections

---

### Recherche Binaire (Binary Search)

**D√©finition** : Algorithme de recherche efficace qui fonctionne sur un **tableau tri√©** en divisant r√©p√©titivement l'espace de recherche par deux.

**Pr√©requis** : Le tableau DOIT √™tre tri√©.

**Complexit√©** :

- **Temps** : O(log n)
- **Espace** : O(1) pour la version it√©rative, O(log n) pour la version r√©cursive

**Principe** :

1. Comparer l'√©l√©ment du milieu avec la cible
2. Si √©gal ‚Üí trouv√©
3. Si cible < milieu ‚Üí chercher dans la moiti√© gauche
4. Si cible > milieu ‚Üí chercher dans la moiti√© droite
5. R√©p√©ter jusqu'√† trouver ou √©puiser l'espace

**Impl√©mentation it√©rative** :

```javascript
function rechercheBinaire(arr, cible) {
  let debut = 0;
  let fin = arr.length - 1;

  while (debut <= fin) {
    const milieu = Math.floor((debut + fin) / 2);

    if (arr[milieu] === cible) {
      return milieu;
    } else if (arr[milieu] < cible) {
      debut = milieu + 1;
    } else {
      fin = milieu - 1;
    }
  }

  return -1;
}
```

**Impl√©mentation r√©cursive** :

```javascript
function rechercheBinaireRecursive(
  arr,
  cible,
  debut = 0,
  fin = arr.length - 1,
) {
  if (debut > fin) return -1;

  const milieu = Math.floor((debut + fin) / 2);

  if (arr[milieu] === cible) return milieu;
  if (arr[milieu] < cible)
    return rechercheBinaireRecursive(arr, cible, milieu + 1, fin);
  return rechercheBinaireRecursive(arr, cible, debut, milieu - 1);
}
```

**Exemple de croissance** :

- 1 000 √©l√©ments ‚Üí ~10 comparaisons maximum
- 1 000 000 √©l√©ments ‚Üí ~20 comparaisons maximum
- 1 000 000 000 √©l√©ments ‚Üí ~30 comparaisons maximum

---

### R√©cursion

**D√©finition** : Technique de programmation o√π une fonction **s'appelle elle-m√™me** pour r√©soudre un probl√®me en le d√©composant en sous-probl√®mes plus petits et similaires.

**Composants essentiels** :

1. **Cas de base** : Condition d'arr√™t qui termine la r√©cursion
2. **Cas r√©cursif** : Appel de la fonction sur un sous-probl√®me plus petit

**Exemple - Factorielle** :

```javascript
function factorielle(n) {
  // Cas de base
  if (n === 0 || n === 1) return 1;

  // Cas r√©cursif
  return n * factorielle(n - 1);
}
```

**Avantages** :

- Code plus √©l√©gant et lisible pour certains probl√®mes
- Naturelle pour structures r√©cursives (arbres, graphes)
- Simplifie diviser-pour-r√©gner

**Inconv√©nients** :

- Risque de stack overflow pour r√©cursions profondes
- Peut √™tre moins performante que les solutions it√©ratives
- Consomme plus de m√©moire (pile d'appels)

---

### Cas de Base (Base Case)

**D√©finition** : Condition qui **arr√™te** la r√©cursion en retournant une valeur directe sans effectuer d'appel r√©cursif suppl√©mentaire.

**Importance** : Sans cas de base, la r√©cursion s'ex√©cuterait ind√©finiment (r√©cursion infinie ‚Üí stack overflow).

**Exemple** :

```javascript
function fibonacci(n) {
  if (n <= 1) return n; // Cas de base
  return fibonacci(n - 1) + fibonacci(n - 2); // Cas r√©cursif
}
```

---

### Pile d'Appels (Call Stack)

**D√©finition** : Structure de donn√©es de type **pile** utilis√©e par le runtime JavaScript pour g√©rer les appels de fonctions. Chaque appel de fonction ajoute un **cadre d'ex√©cution** (stack frame) sur la pile.

**Fonctionnement** :

1. Appel de fonction ‚Üí nouveau cadre ajout√© sur la pile
2. Retour de fonction ‚Üí cadre retir√© de la pile
3. La pile suit l'ordre LIFO

**Limite** : Chaque navigateur/environnement a une limite de taille de pile (~10 000 √† 100 000 appels). D√©passer cette limite cause un **stack overflow**.

**Exemple de d√©passement** :

```javascript
function recurInfinie(n) {
  return recurInfinie(n + 1); // Pas de cas de base ‚Üí stack overflow
}
```

---

### Stack Overflow

**D√©finition** : Erreur qui se produit lorsque la **pile d'appels** d√©passe sa taille maximale, g√©n√©ralement caus√©e par une r√©cursion trop profonde ou infinie.

**Erreur JavaScript** : `RangeError: Maximum call stack size exceeded`

**Solutions** :

- Ajouter un cas de base
- Limiter la profondeur de r√©cursion
- Utiliser une approche it√©rative
- Utiliser la m√©mo√Øsation pour √©viter les appels redondants

---

### R√©cursion Terminale (Tail Recursion)

**D√©finition** : Forme optimis√©e de r√©cursion o√π l'appel r√©cursif est la **derni√®re op√©ration** de la fonction (aucune op√©ration apr√®s le retour de l'appel r√©cursif).

**Exemple - Non terminale** :

```javascript
function factorielle(n) {
  if (n === 1) return 1;
  return n * factorielle(n - 1); // Multiplication APR√àS l'appel r√©cursif
}
```

**Exemple - Terminale** :

```javascript
function factorielleTerminale(n, accumulateur = 1) {
  if (n === 1) return accumulateur;
  return factorielleTerminale(n - 1, n * accumulateur); // Appel r√©cursif = derni√®re op√©ration
}
```

**Avantage** : Certains compilateurs/interpr√©teurs peuvent optimiser la r√©cursion terminale (Tail Call Optimization) pour √©viter d'augmenter la pile d'appels.

**Note** : JavaScript moderne (ES6) sp√©cifie l'optimisation des appels terminaux, mais peu de moteurs l'impl√©mentent actuellement.

---

## Module 5 : Arbres et Parcours de Graphes

### Arbre (Tree)

**D√©finition** : Structure de donn√©es **hi√©rarchique** et **non lin√©aire** compos√©e de n≈ìuds connect√©s par des ar√™tes, avec un n≈ìud **racine** unique et sans cycles.

**Caract√©ristiques** :

- Un n≈ìud racine (root)
- Chaque n≈ìud a z√©ro ou plusieurs enfants
- Chaque n≈ìud (sauf la racine) a exactement un parent
- Aucun cycle (pas de boucle)

**Terminologie** :

- **Racine** : N≈ìud au sommet de l'arbre
- **Feuille** : N≈ìud sans enfants
- **N≈ìud interne** : N≈ìud avec au moins un enfant
- **Parent** : N≈ìud directement au-dessus
- **Enfant** : N≈ìud directement en-dessous
- **Fr√®res/Siblings** : N≈ìuds partageant le m√™me parent
- **Anc√™tre** : Parent, grand-parent, etc.
- **Descendant** : Enfant, petit-enfant, etc.

---

### Arbre Binaire (Binary Tree)

**D√©finition** : Arbre o√π chaque n≈ìud a **au maximum 2 enfants** (gauche et droite).

**Structure de n≈ìud** :

```javascript
class NodeBinaire {
  constructor(value) {
    this.value = value;
    this.left = null; // Enfant gauche
    this.right = null; // Enfant droit
  }
}
```

**Types d'arbres binaires** :

- **Arbre binaire complet** : Tous les niveaux sont remplis sauf peut-√™tre le dernier (rempli de gauche √† droite)
- **Arbre binaire parfait** : Tous les niveaux sont compl√®tement remplis
- **Arbre binaire d√©g√©n√©r√©** : Chaque parent a un seul enfant (ressemble √† une liste cha√Æn√©e)

---

### Arbre Binaire de Recherche (Binary Search Tree - BST)

**D√©finition** : Arbre binaire avec la propri√©t√© suivante : pour chaque n≈ìud, tous les √©l√©ments du **sous-arbre gauche** sont inf√©rieurs √† la valeur du n≈ìud, et tous les √©l√©ments du **sous-arbre droit** sont sup√©rieurs.

**Propri√©t√© BST** :

```
     10
    /  \
   5    15
  / \   / \
 3   7 12  20

Gauche < N≈ìud < Droite
```

**Complexit√© des op√©rations** (arbre √©quilibr√©) :

- **Recherche** : O(log n)
- **Insertion** : O(log n)
- **Suppression** : O(log n)

**Complexit√© pire cas** (arbre d√©g√©n√©r√©) :

- Toutes les op√©rations : O(n)

**Impl√©mentation - Insertion** :

```javascript
class BST {
  constructor() {
    this.root = null;
  }

  insert(value) {
    const newNode = new Node(value);

    if (!this.root) {
      this.root = newNode;
      return this;
    }

    let current = this.root;
    while (true) {
      if (value < current.value) {
        if (!current.left) {
          current.left = newNode;
          return this;
        }
        current = current.left;
      } else {
        if (!current.right) {
          current.right = newNode;
          return this;
        }
        current = current.right;
      }
    }
  }

  search(value) {
    let current = this.root;

    while (current) {
      if (value === current.value) return true;
      if (value < current.value) current = current.left;
      else current = current.right;
    }

    return false;
  }
}
```

---

### Profondeur (Depth)

**D√©finition** : Nombre d'ar√™tes depuis la **racine** jusqu'√† un n≈ìud donn√©.

**Exemple** :

```
     10        ‚Üê Profondeur 0 (racine)
    /  \
   5    15     ‚Üê Profondeur 1
  / \
 3   7         ‚Üê Profondeur 2
```

---

### Hauteur (Height)

**D√©finition** : Nombre d'ar√™tes sur le **plus long chemin** depuis un n≈ìud jusqu'√† une feuille.

**Hauteur de l'arbre** : Hauteur de la racine.

**Exemple** :

```
     10        ‚Üê Hauteur 2
    /  \
   5    15     ‚Üê Hauteur 1 (pour 5), Hauteur 0 (pour 15)
  / \
 3   7         ‚Üê Hauteur 0 (feuilles)
```

---

### Niveau (Level)

**D√©finition** : Ensemble des n≈ìuds √† la m√™me profondeur. Le niveau de la racine est 0.

---

### Graphe (Graph)

**D√©finition** : Structure de donn√©es compos√©e de **sommets** (vertices/nodes) connect√©s par des **ar√™tes** (edges). Plus g√©n√©ral qu'un arbre (peut contenir des cycles).

**Types** :

- **Graphe orient√©** : Les ar√™tes ont une direction (A ‚Üí B ‚â† B ‚Üí A)
- **Graphe non orient√©** : Les ar√™tes sont bidirectionnelles (A ‚Äî B = B ‚Äî A)
- **Graphe pond√©r√©** : Les ar√™tes ont des poids/co√ªts
- **Graphe non pond√©r√©** : Toutes les ar√™tes ont le m√™me poids

**Applications** :

- R√©seaux sociaux (amis, followers)
- R√©seaux routiers (villes = sommets, routes = ar√™tes)
- Web (pages = sommets, liens = ar√™tes)
- D√©pendances de packages

---

### Sommet / N≈ìud (Vertex / Node)

**D√©finition** : Entit√© individuelle dans un graphe, repr√©sentant un point ou un objet.

---

### Ar√™te (Edge)

**D√©finition** : Connexion entre deux sommets dans un graphe.

**Types** :

- **Ar√™te orient√©e** : A ‚Üí B (direction d√©finie)
- **Ar√™te non orient√©e** : A ‚Äî B (bidirectionnelle)
- **Ar√™te pond√©r√©e** : Poss√®de un poids/co√ªt

---

### Liste d'Adjacence (Adjacency List)

**D√©finition** : Repr√©sentation d'un graphe o√π chaque sommet stocke une **liste** de ses voisins (sommets adjacents).

**Impl√©mentation** :

```javascript
class Graphe {
  constructor() {
    this.listeAdjacence = {};
  }

  ajouterSommet(sommet) {
    if (!this.listeAdjacence[sommet]) {
      this.listeAdjacence[sommet] = [];
    }
  }

  ajouterArete(sommet1, sommet2) {
    this.listeAdjacence[sommet1].push(sommet2);
    this.listeAdjacence[sommet2].push(sommet1); // Pour graphe non orient√©
  }
}

// Exemple :
// {
//   "A": ["B", "C"],
//   "B": ["A", "D"],
//   "C": ["A", "D"],
//   "D": ["B", "C"]
// }
```

**Avantages** :

- Espace efficace : O(V + E) o√π V = sommets, E = ar√™tes
- Rapide pour parcourir les voisins
- Bon pour graphes peu denses

---

### Matrice d'Adjacence (Adjacency Matrix)

**D√©finition** : Repr√©sentation d'un graphe par une **matrice 2D** o√π `matrice[i][j] = 1` si une ar√™te existe entre le sommet i et le sommet j, sinon `0`.

**Impl√©mentation** :

```javascript
class GrapheMatrice {
  constructor(nombreSommets) {
    this.matrice = Array(nombreSommets)
      .fill(0)
      .map(() => Array(nombreSommets).fill(0));
  }

  ajouterArete(i, j) {
    this.matrice[i][j] = 1;
    this.matrice[j][i] = 1; // Pour graphe non orient√©
  }
}

// Exemple pour graphe A-B-C-D :
// [
//   [0, 1, 1, 0],  // A connect√© √† B et C
//   [1, 0, 0, 1],  // B connect√© √† A et D
//   [1, 0, 0, 1],  // C connect√© √† A et D
//   [0, 1, 1, 0]   // D connect√© √† B et C
// ]
```

**Avantages** :

- V√©rification rapide si ar√™te existe : O(1)
- Simple pour graphes denses

**Inconv√©nients** :

- Espace : O(V¬≤) m√™me si peu d'ar√™tes
- Inefficace pour graphes peu denses

---

### BFS - Parcours en Largeur (Breadth-First Search)

**D√©finition** : Algorithme de parcours de graphe qui explore les sommets **niveau par niveau**, en visitant tous les voisins d'un sommet avant de passer au niveau suivant.

**Principe** : Utilise une **file (Queue)** pour g√©rer l'ordre de visite.

**Complexit√©** :

- **Temps** : O(V + E) o√π V = sommets, E = ar√™tes
- **Espace** : O(V) pour la file et l'ensemble des visit√©s

**Impl√©mentation** :

```javascript
function BFS(graphe, depart) {
  const visites = new Set();
  const file = [depart];
  const resultat = [];

  visites.add(depart);

  while (file.length > 0) {
    const sommet = file.shift();
    resultat.push(sommet);

    for (const voisin of graphe.listeAdjacence[sommet]) {
      if (!visites.has(voisin)) {
        visites.add(voisin);
        file.push(voisin);
      }
    }
  }

  return resultat;
}
```

**Ordre de visite** :

```
     A
    / \
   B   C
  / \   \
 D   E   F

BFS depuis A : A ‚Üí B ‚Üí C ‚Üí D ‚Üí E ‚Üí F
```

**Cas d'usage** :

- Trouver le **plus court chemin** (en nombre d'ar√™tes)
- Parcours niveau par niveau
- R√©seau social (amis √† distance k)
- R√©solution de labyrinthes

---

### DFS - Parcours en Profondeur (Depth-First Search)

**D√©finition** : Algorithme de parcours de graphe qui explore en **profondeur** en suivant une branche jusqu'au bout avant de revenir en arri√®re (backtracking).

**Principe** : Utilise une **pile (Stack)** ou la **r√©cursion** pour g√©rer l'ordre de visite.

**Complexit√©** :

- **Temps** : O(V + E)
- **Espace** : O(V) pour la pile/r√©cursion et l'ensemble des visit√©s

**Impl√©mentation r√©cursive** :

```javascript
function DFS(graphe, depart, visites = new Set(), resultat = []) {
  visites.add(depart);
  resultat.push(depart);

  for (const voisin of graphe.listeAdjacence[depart]) {
    if (!visites.has(voisin)) {
      DFS(graphe, voisin, visites, resultat);
    }
  }

  return resultat;
}
```

**Impl√©mentation it√©rative** :

```javascript
function DFSIterative(graphe, depart) {
  const visites = new Set();
  const pile = [depart];
  const resultat = [];

  while (pile.length > 0) {
    const sommet = pile.pop();

    if (!visites.has(sommet)) {
      visites.add(sommet);
      resultat.push(sommet);

      for (const voisin of graphe.listeAdjacence[sommet]) {
        if (!visites.has(voisin)) {
          pile.push(voisin);
        }
      }
    }
  }

  return resultat;
}
```

**Ordre de visite** :

```
     A
    / \
   B   C
  / \   \
 D   E   F

DFS depuis A : A ‚Üí B ‚Üí D ‚Üí E ‚Üí C ‚Üí F (r√©cursif)
```

**Cas d'usage** :

- D√©tection de cycles
- Tri topologique
- R√©solution de labyrinthes
- Parcours d'arbres (pr√©-ordre, en-ordre, post-ordre)
- R√©solution de puzzles (Sudoku, √©checs)

---

### Parcours Pr√©-ordre (Pre-order)

**D√©finition** : Parcours d'arbre qui visite les n≈ìuds dans l'ordre : **Racine ‚Üí Gauche ‚Üí Droite**

**Impl√©mentation** :

```javascript
function parcoursPreOrdre(node) {
  if (!node) return;
  console.log(node.value); // Visiter racine
  parcoursPreOrdre(node.left); // Parcourir gauche
  parcoursPreOrdre(node.right); // Parcourir droite
}
```

**Usage** : Cr√©er une copie de l'arbre, √©valuation d'expressions pr√©fix√©es

---

### Parcours En-ordre (In-order)

**D√©finition** : Parcours d'arbre qui visite les n≈ìuds dans l'ordre : **Gauche ‚Üí Racine ‚Üí Droite**

**Impl√©mentation** :

```javascript
function parcoursEnOrdre(node) {
  if (!node) return;
  parcoursEnOrdre(node.left); // Parcourir gauche
  console.log(node.value); // Visiter racine
  parcoursEnOrdre(node.right); // Parcourir droite
}
```

**Usage** : Obtenir les valeurs d'un BST dans l'ordre tri√©

---

### Parcours Post-ordre (Post-order)

**D√©finition** : Parcours d'arbre qui visite les n≈ìuds dans l'ordre : **Gauche ‚Üí Droite ‚Üí Racine**

**Impl√©mentation** :

```javascript
function parcoursPostOrdre(node) {
  if (!node) return;
  parcoursPostOrdre(node.left); // Parcourir gauche
  parcoursPostOrdre(node.right); // Parcourir droite
  console.log(node.value); // Visiter racine
}
```

**Usage** : Supprimer un arbre, √©valuation d'expressions postfix√©es

---

## Module 6 : Paradigmes Avanc√©s de Conception d'Algorithmes

### Algorithme Glouton (Greedy Algorithm)

**D√©finition** : Paradigme de conception d'algorithmes qui fait le **meilleur choix localement optimal** √† chaque √©tape, en esp√©rant que cela m√®ne √† une **solution globalement optimale**.

**Propri√©t√©s n√©cessaires** :

1. **Propri√©t√© de choix glouton** : Un choix localement optimal m√®ne √† une solution globalement optimale
2. **Sous-structure optimale** : La solution optimale contient des solutions optimales de sous-probl√®mes

**Complexit√©** : G√©n√©ralement O(n log n) √† cause du tri initial

**Exemples classiques** :

- Probl√®me de la monnaie (certains syst√®mes mon√©taires)
- S√©lection d'activit√©s
- Sac √† dos fractionnaire
- Arbre couvrant minimal (Kruskal, Prim)
- Plus court chemin (Dijkstra)

**Impl√©mentation - Rendu de monnaie** :

```javascript
function renduMonnaieGlouton(montant, pieces) {
  pieces.sort((a, b) => b - a); // Trier par ordre d√©croissant
  const resultat = [];

  for (const piece of pieces) {
    while (montant >= piece) {
      resultat.push(piece);
      montant -= piece;
    }
  }

  return resultat;
}

// Exemple : renduMonnaieGlouton(63, [25, 10, 5, 1])
// R√©sultat : [25, 25, 10, 1, 1, 1] (6 pi√®ces)
```

**Avantages** :

- Simple √† concevoir et impl√©menter
- G√©n√©ralement rapide (O(n log n))
- Efficace pour certains probl√®mes

**Limitations** :

- Ne garantit PAS toujours la solution optimale
- N√©cessite de prouver que le choix glouton fonctionne
- Ne fonctionne pas pour tous les probl√®mes (ex: sac √† dos 0/1)

---

### Programmation Dynamique (Dynamic Programming - DP)

**D√©finition** : Paradigme de conception d'algorithmes qui r√©sout des probl√®mes en les d√©composant en **sous-probl√®mes chevauchants** et en **stockant les r√©sultats** pour √©viter les calculs redondants.

**Propri√©t√©s n√©cessaires** :

1. **Sous-probl√®mes chevauchants** : Le probl√®me peut √™tre d√©compos√© en sous-probl√®mes r√©utilis√©s plusieurs fois
2. **Sous-structure optimale** : La solution optimale contient des solutions optimales de sous-probl√®mes

**Deux approches** :

- **M√©mo√Øsation (Top-down)** : R√©cursif + cache
- **Tabulation (Bottom-up)** : It√©ratif + table DP

**Complexit√©** : G√©n√©ralement O(n √ó k) o√π k d√©pend du probl√®me

**Exemples classiques** :

- Fibonacci
- Sac √† dos 0/1
- Plus longue sous-s√©quence commune (LCS)
- Rendu de monnaie (version optimale)
- Voyageur sur grille
- Coupe de b√¢ton (rod cutting)

---

### Sous-probl√®mes Chevauchants (Overlapping Subproblems)

**D√©finition** : Propri√©t√© o√π un probl√®me peut √™tre d√©compos√© en sous-probl√®mes qui sont **r√©solus plusieurs fois**. C'est l'opportunit√© d'optimiser avec la m√©mo√Øsation ou la tabulation.

**Exemple - Fibonacci** :

```
fib(5) appelle fib(4) et fib(3)
fib(4) appelle fib(3) et fib(2)
‚Üí fib(3) est calcul√© 2 fois
‚Üí fib(2) est calcul√© 3 fois
‚Üí fib(1) est calcul√© 5 fois

Avec m√©mo√Øsation : chaque fib(n) n'est calcul√© qu'une seule fois
```

---

### Sous-structure Optimale (Optimal Substructure)

**D√©finition** : Propri√©t√© o√π la **solution optimale** d'un probl√®me peut √™tre construite √† partir des **solutions optimales** de ses sous-probl√®mes.

**Exemple - Plus court chemin** :

```
Le plus court chemin de A √† C passant par B =
  Plus court chemin de A √† B + Plus court chemin de B √† C
```

**Contre-exemple - Plus long chemin simple** :
Le plus long chemin simple ne poss√®de PAS cette propri√©t√© car ajouter un sous-chemin optimal peut cr√©er un cycle.

---

### M√©mo√Øsation (Memoization)

**D√©finition** : Technique d'optimisation **top-down** (descendante) qui consiste √† **cacher les r√©sultats** des appels de fonction pour √©viter de recalculer les m√™mes sous-probl√®mes.

**Principe** : R√©cursion + Cache (Map/Object)

**Impl√©mentation - Fibonacci** :

```javascript
function fibonacciMemo(n, memo = {}) {
  // Cas de base
  if (n <= 1) return n;

  // V√©rifier le cache
  if (memo[n] !== undefined) return memo[n];

  // Calculer et stocker dans le cache
  memo[n] = fibonacciMemo(n - 1, memo) + fibonacciMemo(n - 2, memo);

  return memo[n];
}

// Complexit√© : O(2^n) ‚Üí O(n)
```

**Avantages** :

- Approche naturelle (r√©cursive)
- Ne calcule que les sous-probl√®mes n√©cessaires
- Facile √† impl√©menter √† partir d'une solution r√©cursive na√Øve

**Inconv√©nients** :

- Utilise la pile d'appels (risque de stack overflow)
- Peut consommer plus de m√©moire si tous les sous-probl√®mes sont explor√©s

---

### Tabulation

**D√©finition** : Technique de programmation dynamique **bottom-up** (ascendante) qui construit une **table DP** en r√©solvant les sous-probl√®mes des plus petits aux plus grands, de mani√®re it√©rative.

**Principe** : It√©ration + Table DP (Array)

**Impl√©mentation - Fibonacci** :

```javascript
function fibonacciTabulation(n) {
  if (n <= 1) return n;

  const dp = Array(n + 1);
  dp[0] = 0;
  dp[1] = 1;

  for (let i = 2; i <= n; i++) {
    dp[i] = dp[i - 1] + dp[i - 2];
  }

  return dp[n];
}

// Complexit√© : Temps O(n), Espace O(n)
```

**Avantages** :

- Pas de pile d'appels (pas de risque de stack overflow)
- Souvent plus rapide (meilleure localit√© m√©moire)
- Contr√¥le total sur l'ordre de calcul

**Inconv√©nients** :

- Moins intuitif que la r√©cursion
- Calcule tous les sous-probl√®mes m√™me si certains ne sont pas n√©cessaires

---

### Table DP

**D√©finition** : Tableau (ou matrice) utilis√© en tabulation pour **stocker les solutions** de tous les sous-probl√®mes, construit de bas en haut.

**Exemple - Sac √† dos 0/1** :

```javascript
// dp[i][w] = valeur maximale avec les i premiers objets et capacit√© w
const dp = Array(n + 1)
  .fill(0)
  .map(() => Array(W + 1).fill(0));

for (let i = 1; i <= n; i++) {
  for (let w = 1; w <= W; w++) {
    if (weights[i - 1] <= w) {
      dp[i][w] = Math.max(
        dp[i - 1][w], // Ne pas prendre l'objet
        values[i - 1] + dp[i - 1][w - weights[i - 1]], // Prendre l'objet
      );
    } else {
      dp[i][w] = dp[i - 1][w];
    }
  }
}
```

---

### Sac √† dos 0/1 (0/1 Knapsack)

**D√©finition** : Probl√®me d'optimisation o√π on doit s√©lectionner des objets (chacun avec un poids et une valeur) pour maximiser la valeur totale sans d√©passer une capacit√© donn√©e. Chaque objet peut √™tre pris (1) ou non (0), pas de fractions.

**Formulation** :

- Entr√©e : n objets avec poids[i] et valeurs[i], capacit√© W
- Sortie : Valeur maximale r√©alisable

**Solution DP** :

```
dp[i][w] = max(
  dp[i-1][w],                      // Ne pas prendre l'objet i
  values[i] + dp[i-1][w-poids[i]]  // Prendre l'objet i
)
```

**Complexit√©** : O(nW) - Pseudo-polynomiale

**Note** : Contrairement au sac √† dos fractionnaire, l'approche gloutonne ne fonctionne PAS pour le sac √† dos 0/1.

---

### Sac √† dos Fractionnaire (Fractional Knapsack)

**D√©finition** : Variante du sac √† dos o√π on peut prendre des **fractions** d'objets. L'approche **gloutonne** (trier par ratio valeur/poids) donne la solution optimale.

**Complexit√©** : O(n log n) (√† cause du tri)

---

### Complexit√© Pseudo-polynomiale

**D√©finition** : Complexit√© qui semble polynomiale mais d√©pend de la **valeur num√©rique** d'une entr√©e plut√¥t que de sa **taille en bits**.

**Exemple** : Le sac √† dos 0/1 avec complexit√© O(nW) est pseudo-polynomial car W peut √™tre exponentiel par rapport √† sa taille en bits.

- Si W = 1000 (encod√© sur ~10 bits), O(nW) semble raisonnable
- Si W = 10^9 (encod√© sur ~30 bits), O(nW) devient impraticable

---

### Top-down vs Bottom-up

**D√©finition** : Deux approches de la programmation dynamique.

| Aspect             | Top-down (M√©mo√Øsation)                | Bottom-up (Tabulation)                 |
| ------------------ | ------------------------------------- | -------------------------------------- |
| **Style**          | R√©cursif                              | It√©ratif                               |
| **Direction**      | Du probl√®me vers les cas de base      | Des cas de base vers le probl√®me       |
| **Structure**      | Cache (Map/Object)                    | Table DP (Array)                       |
| **Sous-probl√®mes** | Calcule uniquement ceux n√©cessaires   | Calcule tous les sous-probl√®mes        |
| **Pile d'appels**  | Oui (risque stack overflow)           | Non                                    |
| **Performance**    | Parfois plus lent (overhead r√©cursif) | Souvent plus rapide (localit√© m√©moire) |
| **Intuitivit√©**    | Plus naturel pour probl√®mes r√©cursifs | Plus difficile √† concevoir             |

---

## Module 7 : R√©vision et Pratique Avanc√©e

### Pattern Two Pointers (Deux Pointeurs)

**D√©finition** : Technique algorithmique utilisant **deux pointeurs** qui parcourent une structure de donn√©es (souvent un tableau) pour r√©soudre un probl√®me efficacement.

**Variantes** :

- **Pointeurs oppos√©s** : D√©but et fin se rapprochent (ex: v√©rifier palindrome)
- **Pointeurs dans le m√™me sens** : Deux pointeurs avancent √† des vitesses diff√©rentes (ex: supprimer doublons)

**Exemple - Somme de deux nombres (tableau tri√©)** :

```javascript
function sommeDeux(arr, cible) {
  let gauche = 0;
  let droite = arr.length - 1;

  while (gauche < droite) {
    const somme = arr[gauche] + arr[droite];

    if (somme === cible) {
      return [gauche, droite];
    } else if (somme < cible) {
      gauche++;
    } else {
      droite--;
    }
  }

  return null;
}
```

**Complexit√©** : O(n) au lieu de O(n¬≤) avec deux boucles imbriqu√©es

---

### Pattern Sliding Window (Fen√™tre Glissante)

**D√©finition** : Technique qui utilise une **fen√™tre** (sous-ensemble contigu) qui se d√©place sur les donn√©es pour optimiser le calcul d'agr√©gats.

**Principe** : Au lieu de recalculer tout √† chaque √©tape, on retire l'√©l√©ment qui sort de la fen√™tre et on ajoute celui qui entre.

**Exemple - Somme maximale d'un sous-tableau de taille k** :

```javascript
function sommeMaxFenetre(arr, k) {
  if (arr.length < k) return null;

  // Calculer la somme de la premi√®re fen√™tre
  let sommeActuelle = 0;
  for (let i = 0; i < k; i++) {
    sommeActuelle += arr[i];
  }

  let sommeMax = sommeActuelle;

  // Faire glisser la fen√™tre
  for (let i = k; i < arr.length; i++) {
    sommeActuelle = sommeActuelle - arr[i - k] + arr[i];
    sommeMax = Math.max(sommeMax, sommeActuelle);
  }

  return sommeMax;
}
```

**Complexit√©** : O(n) au lieu de O(n√ók)

---

### Optimisation Pr√©matur√©e

**D√©finition** : Pratique de tenter d'optimiser le code **trop t√¥t** dans le processus de d√©veloppement, avant m√™me de savoir si l'optimisation est n√©cessaire.

**Citation c√©l√®bre** : "Premature optimization is the root of all evil" - Donald Knuth

**Approche recommand√©e** :

1. **D'abord** : √âcrire un code correct et lisible
2. **Ensuite** : Mesurer les performances (profiling)
3. **Enfin** : Optimiser uniquement les goulots d'√©tranglement identifi√©s

---

### Profiling (Profilage)

**D√©finition** : Processus de **mesure des performances** d'un programme pour identifier les parties qui consomment le plus de temps ou de m√©moire (goulots d'√©tranglement).

**Outils JavaScript** :

- `console.time()` / `console.timeEnd()`
- Chrome DevTools Performance tab
- Node.js `--prof` flag
- `performance.now()`

**Exemple** :

```javascript
console.time("Tri");
triRapide(largeArray);
console.timeEnd("Tri");
// Tri: 15.234ms
```

---

### Goulot d'√âtranglement (Bottleneck)

**D√©finition** : Partie d'un algorithme ou syst√®me qui **limite les performances globales**. C'est la section la plus lente qui d√©termine la vitesse totale.

**Identification** : Utiliser le profiling pour d√©tecter o√π le code passe le plus de temps.

---

### Compromis Temps-Espace (Time-Space Tradeoff)

**D√©finition** : Principe selon lequel on peut souvent **√©changer** de la m√©moire contre du temps de calcul, ou vice versa.

**Exemples** :

- **M√©mo√Øsation** : Utilise plus d'espace O(n) pour r√©duire le temps O(2^n) ‚Üí O(n)
- **Tabulation optimis√©e** : R√©duit l'espace O(n) ‚Üí O(1) en gardant seulement les k derni√®res valeurs
- **Cache** : Stocke des r√©sultats en m√©moire pour √©viter les recalculs

**D√©cision** : D√©pend des contraintes du probl√®me (m√©moire limit√©e vs temps limit√©)

---

### Cache / Mise en Cache (Caching)

**D√©finition** : Technique de stockage temporaire de **r√©sultats** ou **donn√©es fr√©quemment utilis√©es** pour am√©liorer les performances en √©vitant des calculs ou acc√®s r√©p√©t√©s.

**Types** :

- **M√©mo√Øsation** : Cache des r√©sultats de fonctions
- **Cache HTTP** : Stocke des r√©ponses d'API
- **Cache navigateur** : Stocke des fichiers statiques

---

### Invariant de Boucle (Loop Invariant)

**D√©finition** : Propri√©t√© qui reste **vraie** avant et apr√®s chaque it√©ration d'une boucle. Utilis√© pour prouver la **correction** d'un algorithme.

**Exemple - Recherche lin√©aire** :

```javascript
function recherche(arr, cible) {
  for (let i = 0; i < arr.length; i++) {
    // Invariant : cible n'est pas dans arr[0...i-1]
    if (arr[i] === cible) return i;
  }
  return -1;
}
```

---

### Programmation Comp√©titive (Competitive Programming)

**D√©finition** : Sport intellectuel o√π les participants r√©solvent des **probl√®mes algorithmiques** sous contraintes de temps, testant la conception d'algorithmes, les structures de donn√©es et l'impl√©mentation rapide.

**Plateformes** :

- LeetCode
- HackerRank
- Codeforces
- CodeChef
- AtCoder
- TopCoder

**Comp√©titions** :

- Google Code Jam
- Meta Hacker Cup
- ACM ICPC (International Collegiate Programming Contest)

---

### Complexit√© Amortie (Amortized Complexity)

**D√©finition** : Complexit√© **moyenne** d'une op√©ration sur une **s√©quence** d'op√©rations, m√™me si certaines op√©rations individuelles peuvent √™tre co√ªteuses.

**Exemple - push() dans un tableau dynamique** :

- La plupart des push() sont O(1)
- Parfois, il faut redimensionner le tableau ‚Üí O(n)
- **Complexit√© amortie** : O(1) car le redimensionnement est rare

---

## üîó Termes G√©n√©raux

### Correctness (Correction)

**D√©finition** : Propri√©t√© d'un algorithme qui **produit le r√©sultat attendu** pour toutes les entr√©es valides.

**Preuves de correction** :

- Preuves math√©matiques
- Invariants de boucle
- Induction math√©matique
- Tests exhaustifs

---

### D√©terministe

**D√©finition** : Un algorithme est **d√©terministe** si, pour une m√™me entr√©e, il produit toujours la m√™me sortie en suivant les m√™mes √©tapes.

**Contraire** : Algorithme **probabiliste** ou **randomis√©** (ex: Quick Sort avec pivot al√©atoire)

---

### In-Situ / En Place (In-Place)

**D√©finition** : Un algorithme qui modifie la structure de donn√©es d'entr√©e **sans utiliser** de m√©moire suppl√©mentaire significative (seulement O(1) espace auxiliaire).

**Exemples** : Tri rapide, tri par insertion, tri √† bulles

---

### Stable

**D√©finition** : Un algorithme de tri est **stable** s'il **pr√©serve l'ordre relatif** des √©l√©ments ayant la m√™me cl√© de tri.

**Exemple** :

```javascript
// Donn√©es : [{nom: "Chermann", √¢ge: 43}, {nom: "Prudence", √¢ge: 45}]
// Tri stable par √¢ge ‚Üí L'ordre Chermann-Prudence est pr√©serv√©
```

**Tris stables** : Tri fusion, tri par insertion, tri √† bulles
**Tris non stables** : Tri rapide, tri par s√©lection, tri par tas

---

### It√©ratif

**D√©finition** : Approche utilisant des **boucles** (for, while) pour r√©p√©ter des op√©rations.

**Avantages** :

- Pas de pile d'appels
- Souvent plus rapide
- Pas de risque de stack overflow

---

### R√©cursif

**D√©finition** : Approche o√π une fonction **s'appelle elle-m√™me** pour r√©soudre un probl√®me.

**Avantages** :

- Code plus √©l√©gant pour probl√®mes naturellement r√©cursifs
- Simplifie diviser-pour-r√©gner

**Inconv√©nients** :

- Utilise la pile d'appels
- Risque de stack overflow

---

### Heuristique

**D√©finition** : Technique de r√©solution de probl√®me utilisant une **approche pratique** ou un **raccourci** qui ne garantit pas la solution optimale mais fournit une solution satisfaisante rapidement.

**Exemples** :

- Algorithmes gloutons (heuristiques pour trouver de bonnes solutions)
- A\* (utilise une heuristique pour le pathfinding)

---

### NP-Complet

**D√©finition** : Classe de probl√®mes pour lesquels aucun algorithme polynomial n'est connu, mais une solution propos√©e peut √™tre **v√©rifi√©e** en temps polynomial.

**Exemples** :

- Sac √† dos 0/1
- Voyageur de commerce (TSP)
- Satisfiabilit√© bool√©enne (SAT)
- Coloration de graphe

**Implication** : Pour n grand, ces probl√®mes n√©cessitent des approches approximatives ou heuristiques.

---

### Complexit√© Asymptotique

**D√©finition** : Comportement d'un algorithme lorsque la taille de l'entr√©e **tend vers l'infini**. La notation Big O d√©crit la complexit√© asymptotique.

**Focus** : Termes dominants (on ignore les constantes et termes de moindre ordre)

**Exemple** :

```
5n¬≤ + 3n + 17 ‚Üí O(n¬≤)
```

---

## üìä Tableaux R√©capitulatifs

### Tableau des Complexit√©s Big O

| Notation       | Nom            | Exemple           | n=10    | n=100  | n=1000  | Performance   |
| -------------- | -------------- | ----------------- | ------- | ------ | ------- | ------------- |
| **O(1)**       | Constante      | Acc√®s tableau     | 1       | 1      | 1       | Excellente    |
| **O(log n)**   | Logarithmique  | Recherche binaire | 3       | 7      | 10      | Tr√®s bonne    |
| **O(n)**       | Lin√©aire       | Parcours tableau  | 10      | 100    | 1000    | Bonne         |
| **O(n log n)** | Quasi-lin√©aire | Tri fusion        | 30      | 700    | 10000   | Acceptable    |
| **O(n¬≤)**      | Quadratique    | Tri √† bulles      | 100     | 10000  | 1000000 | Passable      |
| **O(2‚Åø)**      | Exponentielle  | Fibonacci na√Øf    | 1024    | ~10¬≥‚Å∞  | ~10¬≥‚Å∞‚Å∞  | Tr√®s mauvaise |
| **O(n!)**      | Factorielle    | Permutations      | 3628800 | ~10¬π‚Åµ‚Å∑ | ~10¬≤‚Åµ‚Å∂‚Å∑ | Impraticable  |

---

### Comparaison des Algorithmes de Tri

| Algorithme        | Meilleur Cas | Cas Moyen  | Pire Cas   | Espace   | Stable | Usage              |
| ----------------- | ------------ | ---------- | ---------- | -------- | ------ | ------------------ |
| **Tri √† Bulles**  | O(n)         | O(n¬≤)      | O(n¬≤)      | O(1)     | ‚úÖ     | P√©dagogique        |
| **Tri S√©lection** | O(n¬≤)        | O(n¬≤)      | O(n¬≤)      | O(1)     | ‚ùå     | Rarement           |
| **Tri Insertion** | O(n)         | O(n¬≤)      | O(n¬≤)      | O(1)     | ‚úÖ     | Petits tableaux    |
| **Tri Fusion**    | O(n log n)   | O(n log n) | O(n log n) | O(n)     | ‚úÖ     | Grandes donn√©es    |
| **Tri Rapide**    | O(n log n)   | O(n log n) | O(n¬≤)      | O(log n) | ‚ùå     | G√©n√©ral (meilleur) |

---

### Comparaison des Structures de Donn√©es

| Structure            | Acc√®s    | Recherche | Insertion | Suppression | Espace |
| -------------------- | -------- | --------- | --------- | ----------- | ------ |
| **Tableau**          | O(1)     | O(n)      | O(n)      | O(n)        | O(n)   |
| **Liste Cha√Æn√©e**    | O(n)     | O(n)      | O(1)\*    | O(1)\*      | O(n)   |
| **Pile**             | O(n)     | O(n)      | O(1)      | O(1)        | O(n)   |
| **File**             | O(n)     | O(n)      | O(1)      | O(1)        | O(n)   |
| **BST (√©quilibr√©)**  | O(log n) | O(log n)  | O(log n)  | O(log n)    | O(n)   |
| **Table de Hachage** | -        | O(1)\*\*  | O(1)\*\*  | O(1)\*\*    | O(n)   |

_\* En t√™te de liste
\*\* Cas moyen, pire cas O(n)_

---

### Comparaison M√©mo√Øsation vs Tabulation

| Aspect             | M√©mo√Øsation (Top-down)                  | Tabulation (Bottom-up)                                 |
| ------------------ | --------------------------------------- | ------------------------------------------------------ |
| **Approche**       | R√©cursive                               | It√©rative                                              |
| **Direction**      | Probl√®me ‚Üí Cas de base                  | Cas de base ‚Üí Probl√®me                                 |
| **Stockage**       | Cache (Map/Object)                      | Table DP (Array)                                       |
| **Sous-probl√®mes** | Seulement n√©cessaires                   | Tous                                                   |
| **Pile d'appels**  | Oui (risque stack overflow)             | Non                                                    |
| **Impl√©mentation** | Plus facile (ajouter cache √† r√©cursion) | Plus difficile                                         |
| **Performance**    | Overhead r√©cursif                       | Meilleure localit√© m√©moire                             |
| **Quand utiliser** | Structure r√©cursive naturelle           | Grande profondeur, tous les sous-probl√®mes n√©cessaires |

---

## üéì Conclusion

Ce glossaire couvre les **42 le√ßons** des **7 modules** de la formation. Il est con√ßu pour √™tre une **r√©f√©rence rapide** lors de vos r√©visions ou de la r√©solution de probl√®mes algorithmiques.

**Conseils d'utilisation** :

- üìñ Utilisez Ctrl+F / Cmd+F pour rechercher un terme sp√©cifique
- üîÑ R√©visez r√©guli√®rement les complexit√©s et patterns
- üí° Reliez les termes entre eux pour comprendre les connexions
- üéØ Pratiquez avec des exemples de code pour chaque concept
- üìö R√©f√©rez-vous aux le√ßons compl√®tes pour approfondir

**Modules compl√©mentaires** :

- [README.md](README.md) - Vue d'ensemble du cours

---

**Derni√®re mise √† jour** : 2026-01-24

**Bonne r√©vision et bon codage !** üöÄ
